{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b552b5f0",
   "metadata": {},
   "source": [
    "# Deep Research System\n",
    "\n",
    "This notebook implements a deep research system using LangGraph that performs comprehensive research on a query by:\n",
    "1. Search Planner: Using LLM to create multiple search items\n",
    "2. Search Agent: Searching each item on the web and summarizing results\n",
    "3. Final Report: Generating a comprehensive report from the summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ac244",
   "metadata": {},
   "source": [
    "### Imports and Setup\n",
    "\n",
    "Import required libraries for the deep research agent, including LangChain for tools and embeddings, LangGraph for stateful graphs, and Pydantic for structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27eb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "from typing import Annotated, TypedDict, List, Dict\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bf589",
   "metadata": {},
   "source": [
    "### Agent State\n",
    "\n",
    "Defines DeepResearchState as a typed dictionary to persist state across the LangGraph workflow, including messages, search queries, search results, and final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80a1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Agent State ---\n",
    "class DeepResearchState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], operator.add]\n",
    "    original_query: str\n",
    "    search_queries: List[str]\n",
    "    search_results: Dict[str, str]  # query -> summary\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c187eb",
   "metadata": {},
   "source": [
    "### Tool Definitions\n",
    "\n",
    "Defines tools for web search (using Serper API) to enable the agent to call them dynamically in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b47c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchQuery(BaseModel):\n",
    "    query: str = Field(description=\"Search query for web search\")\n",
    "\n",
    "\n",
    "@tool(args_schema=SearchQuery)\n",
    "def web_search_tool(query: str):\n",
    "    \"\"\"Get real-time Internet information using Serper API\"\"\"\n",
    "    # Get API key from environment variable or use placeholder\n",
    "    api_key = os.environ.get('SERPER_API_KEY', 'YOUR_SERPER_API_KEY')\n",
    "    \n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "        \"q\": query,\n",
    "        \"num\": 5,  # Get 5 results\n",
    "    })\n",
    "    headers = {\n",
    "      'X-API-KEY': 'd6205f8378e105dc9afdcb2dbbd44521c716b9c4',\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=payload, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'organic' in data:\n",
    "            results = []\n",
    "            for item in data['organic'][:3]:  # Take top 3 results\n",
    "                result = {\n",
    "                    'title': item.get('title', ''),\n",
    "                    'snippet': item.get('snippet', ''),\n",
    "                    'link': item.get('link', '')\n",
    "                }\n",
    "                results.append(result)\n",
    "            return json.dumps(results, ensure_ascii=False)\n",
    "        else:\n",
    "            return json.dumps({\"error\": \"No results found\"}, ensure_ascii=False)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return json.dumps({\"error\": f\"Network error occurred: {str(e)}\"}, ensure_ascii=False)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return json.dumps({\"error\": f\"Failed to parse response: {str(e)}\"}, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An unexpected error occurred: {str(e)}\"}, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997d5cb",
   "metadata": {},
   "source": [
    "### LLM Configuration\n",
    "\n",
    "Sets up ChatOpenAI with a local Qwen model, binding tools for structured calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0268aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen3:8b\",\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    openai_api_key=\"<KEY>\",  # Replace with valid key\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([web_search_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775d9bc",
   "metadata": {},
   "source": [
    "### Node Functions\n",
    "\n",
    "Defines node functions for the workflow, including search planning, web search execution, result summarization, and final report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57dfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Planner: Generate multiple search queries from the original query\n",
    "def search_planner(state: DeepResearchState):\n",
    "    \"\"\"\n",
    "    Generates multiple search queries based on the original query using the LLM.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATING SEARCH QUERIES---\")\n",
    "    original_query = state[\"original_query\"]\n",
    "    \n",
    "    planner_prompt = f\"\"\"You are a research query planner. Generate 3-5 diverse search queries that would help research the topic: \"{original_query}\".\n",
    "    Make the queries specific and focused on different aspects of the topic.\n",
    "    Return ONLY a JSON array of strings, nothing else.\n",
    "    \n",
    "    Example format:\n",
    "    [\"query 1\", \"query 2\", \"query 3\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=planner_prompt)])\n",
    "    \n",
    "    try:\n",
    "        # Try to parse as JSON\n",
    "        search_queries = json.loads(response.content)\n",
    "    except:\n",
    "        # If parsing fails, try to extract queries from the text\n",
    "        import re\n",
    "        queries = re.findall(r'\"([^\"]+)\"', response.content)\n",
    "        if not queries:\n",
    "            # Fallback: split by lines or common delimiters\n",
    "            queries = [q.strip('\"') for q in response.content.split('\\n') if q.strip()]\n",
    "        search_queries = queries[:5]  # Limit to 5 queries\n",
    "    \n",
    "    print(f\"Generated queries: {search_queries}\")\n",
    "    return {\"search_queries\": search_queries}\n",
    "\n",
    "# Search Agent: Execute search for each query and summarize results\n",
    "def search_agent(state: DeepResearchState):\n",
    "    \"\"\"\n",
    "    Executes web searches for each query and generates summaries.\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTING WEB SEARCHES---\")\n",
    "    search_queries = state[\"search_queries\"]\n",
    "    search_results = {}\n",
    "    \n",
    "    for query in search_queries:\n",
    "        print(f\"Searching for: {query}\")\n",
    "        try:\n",
    "            # Execute web search\n",
    "            search_result = web_search_tool.invoke({\"query\": query})\n",
    "            search_data = json.loads(search_result)\n",
    "            \n",
    "            # Check for errors in search results\n",
    "            if isinstance(search_data, dict) and \"error\" in search_data:\n",
    "                search_results[query] = f\"Error in search: {search_data['error']}\"\n",
    "                continue\n",
    "            \n",
    "            # Summarize the results\n",
    "            if isinstance(search_data, list) and len(search_data) > 0:\n",
    "                # Format the search results for better summarization\n",
    "                formatted_results = \"\\n\".join([\n",
    "                    f\"Title: {item.get('title', 'N/A')}\\nSnippet: {item.get('snippet', 'N/A')}\\nLink: {item.get('link', 'N/A')}\\n\"\n",
    "                    for item in search_data\n",
    "                ])\n",
    "                \n",
    "                summarization_prompt = f\"\"\"You are a research summarizer. Summarize the following search results for the query \"{query}\". \n",
    "                Provide a comprehensive summary that captures the key points and main ideas from all results.\n",
    "                \n",
    "                Search Results:\n",
    "                {formatted_results}\n",
    "                \n",
    "                Summary:\"\"\"\n",
    "                \n",
    "                summary_response = llm.invoke([HumanMessage(content=summarization_prompt)])\n",
    "                search_results[query] = summary_response.content\n",
    "            else:\n",
    "                search_results[query] = \"No relevant information found for this query.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{query}': {str(e)}\")\n",
    "            search_results[query] = f\"Error occurred while searching: {str(e)}\"\n",
    "    \n",
    "    return {\"search_results\": search_results}\n",
    "\n",
    "# Final Report Generator: Create comprehensive report from summaries\n",
    "def generate_final_report(state: DeepResearchState):\n",
    "    \"\"\"\n",
    "    Generates a final comprehensive report based on all search summaries.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATING FINAL REPORT---\")\n",
    "    original_query = state[\"original_query\"]\n",
    "    search_results = state[\"search_results\"]\n",
    "    \n",
    "    # Check if we have any search results\n",
    "    if not search_results:\n",
    "        final_report = f\"# Research Report: {original_query}\\n\\nNo relevant information could be found for this topic.\"\n",
    "        return {\"final_report\": final_report}\n",
    "    \n",
    "    # Format the search results for the report\n",
    "    formatted_results = \"\\n\\n\".join([f\"## {query}\\n\\n{summary}\" for query, summary in search_results.items()])\n",
    "    \n",
    "    report_prompt = f\"\"\"You are a research report writer. Create a comprehensive report on the topic: \"{original_query}\".\n",
    "    \n",
    "    Use the following research findings to create your report:\n",
    "    \n",
    "{formatted_results}\n",
    "    \n",
    "    Please structure your report with:\n",
    "    1. A title with the original query\n",
    "    2. An introduction explaining the importance of the topic\n",
    "    3. Detailed sections for each research query with key findings (use the query as a subheading)\n",
    "    4. A conclusion summarizing the overall findings and their significance\n",
    "    5. Proper formatting with markdown headers\n",
    "    6. Keep the report professional and well-organized\n",
    "    \n",
    "    Report:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=report_prompt)])\n",
    "    final_report = response.content\n",
    "    \n",
    "    print(\"Final report generated successfully.\")\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2cc17",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Builds the LangGraph workflow by adding nodes, setting entry points, and defining edges for the deep research process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8afbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(DeepResearchState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"search_planner\", search_planner)\n",
    "workflow.add_node(\"search_agent\", search_agent)\n",
    "workflow.add_node(\"generate_final_report\", generate_final_report)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"search_planner\")\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"search_planner\", \"search_agent\")\n",
    "workflow.add_edge(\"search_agent\", \"generate_final_report\")\n",
    "workflow.add_edge(\"generate_final_report\", END)\n",
    "\n",
    "# Compile the graph with error handling\n",
    "try:\n",
    "    graph = workflow.compile()\n",
    "    print(\"Graph compiled successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error compiling graph: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648a6fa",
   "metadata": {},
   "source": [
    "### Test the System\n",
    "\n",
    "Test the graph with sample queries to verify the deep research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c8a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deep research on: What are the latest advancements in quantum computing?\n",
      "==================================================\n",
      "---GENERATING SEARCH QUERIES---\n",
      "Generated queries: ['recent breakthroughs in qubit stability and error correction in quantum computing', 'novel quantum algorithms for optimization and machine learning in 2023', 'latest quantum computing software frameworks and development tools', 'recent studies on quantum supremacy achievements and real-world applications in 2023', 'advances in quantum error correction techniques and scalability challenges in 2023']\n",
      "--- Output from node 'search_planner' ---\n",
      "Generated queries: ['recent breakthroughs in qubit stability and error correction in quantum computing', 'novel quantum algorithms for optimization and machine learning in 2023', 'latest quantum computing software frameworks and development tools', 'recent studies on quantum supremacy achievements and real-world applications in 2023', 'advances in quantum error correction techniques and scalability challenges in 2023']\n",
      "\n",
      "---\n",
      "\n",
      "---EXECUTING WEB SEARCHES---\n",
      "Searching for: recent breakthroughs in qubit stability and error correction in quantum computing\n",
      "Searching for: novel quantum algorithms for optimization and machine learning in 2023\n",
      "Searching for: latest quantum computing software frameworks and development tools\n",
      "Searching for: recent studies on quantum supremacy achievements and real-world applications in 2023\n",
      "Searching for: advances in quantum error correction techniques and scalability challenges in 2023\n",
      "--- Output from node 'search_agent' ---\n",
      "Number of search results: 5\n",
      "\n",
      "---\n",
      "\n",
      "---GENERATING FINAL REPORT---\n",
      "Final report generated successfully.\n",
      "--- Output from node 'generate_final_report' ---\n",
      "Final report generated\n",
      "\n",
      "---\n",
      "\n",
      "---GENERATING SEARCH QUERIES---\n",
      "Generated queries: ['Recent breakthroughs in quantum hardware: qubit scalability and error correction.', 'Latest algorithmic innovations in quantum computing for optimization and machine learning.', 'Advances in quantum error correction techniques and their implementation', 'Current industry applications and case studies of quantum computing in pharmaceuticals and finance.', 'Recent developments in quantum networking and secure communication protocols.']\n",
      "---EXECUTING WEB SEARCHES---\n",
      "Searching for: Recent breakthroughs in quantum hardware: qubit scalability and error correction.\n",
      "Searching for: Latest algorithmic innovations in quantum computing for optimization and machine learning.\n",
      "Searching for: Advances in quantum error correction techniques and their implementation\n",
      "Searching for: Current industry applications and case studies of quantum computing in pharmaceuticals and finance.\n",
      "Searching for: Recent developments in quantum networking and secure communication protocols.\n",
      "---GENERATING FINAL REPORT---\n",
      "Final report generated successfully.\n",
      "===== FINAL REPORT =====\n",
      "<think>\n",
      "Okay, I need to create a structured report based on the user's query. Let me start by understanding the requirements. The user wants a report with specific sections: title, introduction, detailed sections for each research query, a conclusion, and proper formatting with markdown headers. The report should be professional and well-organized.\n",
      "\n",
      "First, the title should include the original query. The original query was about recent developments in quantum networking and secure communication protocols. So the title would be something like \"Recent Developments in Quantum Networking and Secure Communication Protocols: A Comprehensive Overview\".\n",
      "\n",
      "Next, the introduction needs to explain the importance of the topic. I should mention how quantum networking and secure communication protocols are critical for advancing secure data transmission and resilient infrastructure. Highlight the integration of quantum technologies with classical systems and their role in addressing cyber threats and enabling new applications.\n",
      "\n",
      "Now, the detailed sections. The user provided three research queries. Let me check each one again. \n",
      "\n",
      "1. The first query was about quantum networking and secure communication protocols. The search results included DARPA's QuANET initiative, BlueQubit's quantum internet, and NCSC's quantum security technologies. I need to structure each of these as subheadings under the main query. \n",
      "\n",
      "Wait, the user's original query was about quantum networking and secure communication protocols. The three search results are all related to this topic. So the main section for the first query would be \"Quantum Networking and Secure Communication Protocols\", with subheadings for each of the three sources. \n",
      "\n",
      "Wait, the user's initial query was split into three separate research queries. Let me check again. The user's original query was: \"Recent developments in quantum networking and secure communication protocols.\" Then the user provided three search results, each addressing different aspects of this topic. \n",
      "\n",
      "Wait, looking back, the user's original query was about quantum networking and secure communication protocols. The three search results are: \n",
      "1. DARPA's QuANET initiative (combining classical and quantum networks)\n",
      "2. BlueQubit's quantum internet (secure communication via quantum principles)\n",
      "3. NCSC's quantum security technologies (post-quantum cryptography and QKD)\n",
      "\n",
      "So the main section for the first query (quantum networking and secure communication protocols) would include all three sources. However, the user might have intended each search result as a separate query. Wait, looking back, the user's initial message had three separate search results, each with their own query. Wait, no, the user's original query was about quantum networking and secure communication protocols, and then provided three search results. Wait, perhaps the user intended each search result as a separate query. Let me recheck.\n",
      "\n",
      "Wait, the user's original query was: \"Recent developments in quantum networking and secure communication protocols.\" Then the user provided three search results. However, the way the user presented the query and the search results seems like each search result is a separate query. For example, the first search result is about DARPA's QuANET, the second about BlueQubit's quantum internet, and the third about NCSC's quantum security. So the user might have intended three separate queries, each with their own search results. However, the user's initial instruction was to structure the report with sections for each research query. \n",
      "\n",
      "Wait, the user's original query was about quantum networking and secure communication protocols, and then provided three search results. But the way the user presented the query and the search results seems like each search result is a separate query. For example, the first search result is about DARPA's QuANET, the second about BlueQubit's quantum internet, and the third about NCSC's quantum security. Therefore, the user might have intended three separate queries, each with their own search results. However, the initial query was a single topic, and the three search results are all related to it. \n",
      "\n",
      "This is a bit confusing. To clarify, the user's original query is about quantum networking and secure communication protocols, and the three search results are all related to this topic. Therefore, the report should have a single main section for \"Quantum Networking and Secure Communication Protocols\" with sub-sections for each of the three search results. However, the user's instruction says to structure the report with sections for each research query. Since the user provided three search results, each addressing different aspects of the topic, perhaps each search result is a separate query. \n",
      "\n",
      "Alternatively, the user might have intended each search result as a separate query. For example, the first search result is about quantum networking and secure communication protocols (DARPA's QuANET), the second about quantum internet (BlueQubit), and the third about quantum security technologies (NCSC). Therefore, the report should have three sections, each corresponding to a separate query. \n",
      "\n",
      "But the user's original query was about quantum networking and secure communication protocols as a single topic. The three search results are all part of that topic. Therefore, the report should have one main section for the topic, with sub-sections for each search result. \n",
      "\n",
      "To resolve this, I'll structure the report with a main section for \"Quantum Networking and Secure Communication Protocols\" and include the three search results as sub-sections. Each sub-section will detail the key findings from the respective search result. \n",
      "\n",
      "Now, the introduction should explain the importance of quantum networking and secure communication protocols. The conclusion will summarize the overall findings and their significance. \n",
      "\n",
      "I need to ensure that the report is professional, well-organized, and uses markdown headers. The title, introduction, sections, and conclusion should be clearly marked. \n",
      "\n",
      "Let me draft the report accordingly.\n",
      "</think>\n",
      "\n",
      "# Recent Developments in Quantum Networking and Secure Communication Protocols: A Comprehensive Overview  \n",
      "\n",
      "## Introduction  \n",
      "Quantum networking and secure communication protocols represent a transformative frontier in technology, promising to revolutionize data transmission, cybersecurity, and global infrastructure. As quantum computing advances, the integration of quantum mechanics with classical communication systems is critical for addressing emerging threats and enabling new applications. This report synthesizes recent developments in quantum networking and secure communication protocols, highlighting key initiatives, innovations, and their implications for the future of secure data exchange.  \n",
      "\n",
      "---\n",
      "\n",
      "## Quantum Networking and Secure Communication Protocols  \n",
      "\n",
      "### 1. **DARPA’s QuANET Initiative: Hybrid Classical-Quantum Networks**  \n",
      "The **DARPA QuANET** program (August 2025) explores the integration of classical and quantum communication systems to create a **resilient, secure networking infrastructure**. By combining the strengths of both paradigms, this initiative aims to mitigate vulnerabilities in traditional networks while leveraging quantum mechanics for enhanced security. Key focus areas include:  \n",
      "- **Hybrid Network Architectures**: Developing systems that seamlessly integrate quantum key distribution (QKD) with classical communication protocols to ensure robustness against cyber threats.  \n",
      "- **Resilience Against Quantum Threats**: Preparing networks for the eventual dominance of quantum computing by embedding quantum-resistant mechanisms into existing infrastructure.  \n",
      "\n",
      "### 2. **BlueQubit’s Quantum Internet: A New Paradigm for Secure Communication**  \n",
      "The **quantum internet**, as outlined by BlueQubit, envisions a global network based on quantum principles such as **entanglement and superposition**. This framework enables **ultra-secure data transmission**, with applications in:  \n",
      "- **Secure Data Exchange**: Protecting sensitive information through quantum-encrypted channels that are theoretically immune to interception.  \n",
      "- **Global Networking**: Facilitating real-time, tamper-proof communication across continents, with potential impacts on fields like healthcare, finance, and defense.  \n",
      "\n",
      "### 3. **NCSC’s Quantum Security Technologies: Post-Quantum Cryptography and QKD**  \n",
      "The UK’s **National Cyber Security Centre (NCSC)** has released resources on quantum networking technologies, emphasizing their role in **post-quantum cryptography** and **quantum key distribution (QKD)**. These efforts aim to:  \n",
      "- **Mitigate Quantum Threats**: Transitioning to quantum-resistant cryptographic protocols to safeguard critical infrastructure from future quantum computing attacks.  \n",
      "- **Standardization and Implementation**: Advancing the adoption of QKD and post-quantum algorithms to ensure long-term security in both public and private sectors.  \n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion  \n",
      "Recent developments in quantum networking and secure communication protocols underscore a pivotal shift toward **hybrid systems**, **quantum-secure infrastructure**, and **global data protection**. Initiatives like DARPA’s QuANET, BlueQubit’s quantum internet, and the NCSC’s focus on post-quantum cryptography highlight the collaborative efforts to address both current and future cybersecurity challenges. These advancements not only enhance the security of digital communication but also lay the groundwork for a new era of resilient, quantum-enabled networks. As quantum technologies mature, their integration into mainstream systems will be critical for maintaining trust and innovation in an increasingly interconnected world.\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"What are the latest advancements in quantum computing?\"\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"original_query\": query,\n",
    "    \"search_queries\": [],\n",
    "    \"search_results\": {},\n",
    "    \"final_report\": \"\"\n",
    "}\n",
    "\n",
    "# Set the Serper API key (replace with your actual key)\n",
    "# os.environ['SERPER_API_KEY'] = 'your_actual_serper_api_key_here'\n",
    "\n",
    "print(f\"Starting deep research on: {query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    for event in graph.stream(initial_state, {\"recursion_limit\": 25}):\n",
    "        for key, value in event.items():\n",
    "            print(f\"--- Output from node '{key}' ---\")\n",
    "            if key == \"search_planner\":\n",
    "                print(f\"Generated queries: {value.get('search_queries', [])}\")\n",
    "            elif key == \"search_agent\":\n",
    "                print(f\"Number of search results: {len(value.get('search_results', {}))}\")\n",
    "            elif key == \"generate_final_report\":\n",
    "                print(\"Final report generated\")\n",
    "            print(\"\\n---\\n\")\n",
    "\n",
    "    # Display the final report\n",
    "    final_state = list(graph.stream(initial_state, {\"recursion_limit\": 25}))[-1]\n",
    "    print(\"===== FINAL REPORT =====\")\n",
    "    print(final_state['generate_final_report']['final_report'])\n",
    "except Exception as e:\n",
    "    print(f\"Error during deep research: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
